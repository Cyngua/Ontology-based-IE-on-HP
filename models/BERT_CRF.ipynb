{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b806b191-4079-46cd-847a-5e69a94c63e3",
   "metadata": {},
   "source": [
    "# Transformer-CRF Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc89102d-4b2c-49e9-9a4b-66bc27bc497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7dc2fb-f457-4725-9411-4a6e7b61baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f372a978-4e48-495d-8332-4b007948b716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# device='cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15469ae0-b440-4595-868f-1ba7ea3897be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from transformers import EvalPrediction\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1e641e-d619-4285-a32a-92b180c3c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_dataset import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f082ea-a57a-4d5a-b84b-d948c6b2cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training constants\n",
    "MODEL_NAME = 'bert-base-uncased' # let's try bert first\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1057c2b-62ed-4510-83e7-0db98c71d264",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b3762c-cea5-40ef-97d1-9198aefe9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.data.sentence[index]\n",
    "        word_labels = self.data.tags[index]\n",
    "\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                                  is_split_into_words=True,\n",
    "                                  padding='max_length',\n",
    "                                  truncation=True,\n",
    "                                  max_length=self.max_len)\n",
    "\n",
    "        labels = [labels_to_ids[label] for label in word_labels]\n",
    "\n",
    "        encoded_labels = np.ones(len(encoding[\"input_ids\"]), dtype=int) * -100\n",
    "        label_mask = np.zeros(len(encoding[\"input_ids\"]), dtype=bool)\n",
    "        word_ids = encoding.word_ids()\n",
    "\n",
    "        previous_word_idx = None\n",
    "        for idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx is None:\n",
    "                continue\n",
    "            elif word_idx != previous_word_idx:\n",
    "                encoded_labels[idx] = labels[word_idx]\n",
    "                label_mask[idx] = True  # mark this token as valid\n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "        item = {key: torch.tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(encoded_labels)\n",
    "        label_mask[0] = True # force it starts with \"on\"\n",
    "        item['label_mask'] = torch.tensor(label_mask)\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f520dad6-a871-4c28-b6b7-5e5e454dfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = prepare_data(\"../processed_notes.csv\")\n",
    "data = data_dict[\"data\"]\n",
    "labels_to_ids = data_dict[\"labels_to_ids\"]\n",
    "ids_to_labels = data_dict[\"ids_to_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92ee41d-d1bc-44b1-a612-2ecbd9fb3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "NUM_LABELS = len(labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef38fd2-d6d7-4940-a12d-b40b6bb6b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (20305, 4)\n",
      "TRAIN Dataset: (16244, 4)\n",
      "TEST Dataset: (4061, 4)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9c914a-9eed-4266-9dfa-24b20fb28e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4b254d-a0c3-406f-a034-040e3b31aefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-DISO': 1,\n",
       " 'I-DISO': 2,\n",
       " 'B-PROC': 3,\n",
       " 'I-PROC': 4,\n",
       " 'B-ANAT': 5,\n",
       " 'I-ANAT': 6,\n",
       " 'B-UNK': 7,\n",
       " 'B-ACTI': 8,\n",
       " 'I-ACTI': 9,\n",
       " 'B-PHYS': 10,\n",
       " 'I-PHYS': 11,\n",
       " 'B-PHEN': 12,\n",
       " 'I-PHEN': 13,\n",
       " 'B-CONC': 14,\n",
       " 'B-CHEM': 15,\n",
       " 'I-CONC': 16,\n",
       " 'B-OBJC': 17,\n",
       " 'I-UNK': 18,\n",
       " 'B-DEVI': 19,\n",
       " 'I-DEVI': 20,\n",
       " 'B-LIVB': 21,\n",
       " 'I-LIVB': 22}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5c251-9062-4336-94f2-61e5afd6b391",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "253cbafe-3f88-4aef-9c3f-302b66799129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_CRF(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_labels):\n",
    "        super(BERT_CRF, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden2tag = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, label_mask=None):\n",
    "        emissions = self.bert(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask)[0]\n",
    "        emissions = self.dropout(emissions)\n",
    "        emissions = self.hidden2tag(emissions)\n",
    "\n",
    "        if labels is not None:\n",
    "            labels = labels.clone()\n",
    "            labels[labels == -100] = 0  # CRF will ignore these via label_mask\n",
    "            loss = -self.crf(emissions, labels, mask=label_mask.bool(), reduction='mean')\n",
    "            predictions = self.crf.decode(emissions, mask=label_mask.bool())\n",
    "            return loss, predictions\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions, mask=label_mask.bool())\n",
    "            return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47dcbf55-cd43-404a-893b-77e04c51ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.6187, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "model = BERT_CRF(MODEL_NAME, num_labels=NUM_LABELS).to(device)\n",
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0).to(device)\n",
    "labels = inputs[\"labels\"].unsqueeze(0).to(device)\n",
    "label_mask = inputs[\"label_mask\"].unsqueeze(0).to(device)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels, label_mask=label_mask)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc3beeab-8a90-4faa-93dd-77baa0f6e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "model = BERT_CRF(MODEL_NAME, num_labels=NUM_LABELS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83163cdb-60e9-40c9-8459-99cf0b2fdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            label_mask = batch[\"label_mask\"].to(device)\n",
    "\n",
    "            predictions = model(input_ids, attention_mask, labels=None, label_mask=label_mask)\n",
    "\n",
    "            for pred_seq, label_seq, mask_seq in zip(predictions, labels, label_mask):\n",
    "                label_seq = label_seq.cpu().numpy()\n",
    "                mask_seq = mask_seq.cpu().numpy().astype(bool)\n",
    "                mask_seq[0] = False\n",
    "\n",
    "                # Extract only masked tokens\n",
    "                true_label_ids = label_seq[mask_seq]\n",
    "                pred_label_ids = pred_seq[:len(true_label_ids)]  # CRF may return exactly this many\n",
    "\n",
    "                # Sanity check\n",
    "                assert len(true_label_ids) == len(pred_label_ids), \\\n",
    "                    f\"Mismatch in pred/true lengths: {len(pred_label_ids)} vs {len(true_label_ids)}\"\n",
    "\n",
    "                # Map to label strings\n",
    "                all_preds.append([ids_to_labels[p] for p in pred_label_ids])\n",
    "                all_labels.append([ids_to_labels[l] for l in true_label_ids])\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(all_labels, all_preds),\n",
    "        \"precision\": precision_score(all_labels, all_preds, average='macro'),\n",
    "        \"recall\": recall_score(all_labels, all_preds, average='macro'),\n",
    "        \"f1\": f1_score(all_labels, all_preds, average='macro'),\n",
    "        \"f1_all\": f1_score(all_labels, all_preds, average=None),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ec0bd-576c-444e-aa03-1c8e3bf85e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  20%|█▉        | 199/1016 [00:36<02:29,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200: Avg Train Loss = 5.8431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xc392/.conda/envs/clinical-ner/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch 1/3:  20%|█▉        | 201/1016 [00:50<41:33,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200: F1 = 0.0139, Acc = 0.6925, Prec = 0.0125, Recall = 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  39%|███▉      | 399/1016 [01:26<01:51,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400: Avg Train Loss = 5.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  39%|███▉      | 401/1016 [01:40<31:11,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400: F1 = 0.0156, Acc = 0.7038, Prec = 0.0140, Recall = 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  59%|█████▉    | 599/1016 [02:16<01:15,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600: Avg Train Loss = 4.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  59%|█████▉    | 601/1016 [02:30<21:04,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600: F1 = 0.0158, Acc = 0.6956, Prec = 0.0139, Recall = 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  79%|███████▊  | 799/1016 [03:06<00:39,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800: Avg Train Loss = 4.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  79%|███████▉  | 801/1016 [03:20<10:57,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800: F1 = 0.0165, Acc = 0.6874, Prec = 0.0141, Recall = 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  98%|█████████▊| 999/1016 [03:56<00:03,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: Avg Train Loss = 4.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  99%|█████████▊| 1001/1016 [04:10<00:45,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: F1 = 0.0155, Acc = 0.6895, Prec = 0.0136, Recall = 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 1016/1016 [04:13<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed: Avg Training Loss = 4.5415\n",
      "Final: F1 = 0.0169, Acc = 0.6893, Prec = 0.0143, Recall = 0.0207\n",
      "[0.         0.04231166 0.         0.         0.09140738 0.\n",
      " 0.         0.         0.03548681 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  20%|█▉        | 199/1016 [00:36<02:30,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1216: Avg Train Loss = 3.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  20%|█▉        | 201/1016 [00:50<41:34,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1216: F1 = 0.0170, Acc = 0.6689, Prec = 0.0141, Recall = 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  39%|███▉      | 399/1016 [01:26<01:51,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1416: Avg Train Loss = 2.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  39%|███▉      | 401/1016 [01:40<31:16,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1416: F1 = 0.0155, Acc = 0.6777, Prec = 0.0135, Recall = 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  59%|█████▉    | 599/1016 [02:16<01:15,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1616: Avg Train Loss = 2.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  59%|█████▉    | 601/1016 [02:30<21:09,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1616: F1 = 0.0154, Acc = 0.6892, Prec = 0.0137, Recall = 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  79%|███████▊  | 799/1016 [03:06<00:39,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1816: Avg Train Loss = 2.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  79%|███████▉  | 801/1016 [03:20<10:58,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1816: F1 = 0.0166, Acc = 0.6774, Prec = 0.0143, Recall = 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  98%|█████████▊| 999/1016 [03:56<00:03,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2016: Avg Train Loss = 2.7224\n"
     ]
    }
   ],
   "source": [
    "log_every = 200   # log every 50 batches\n",
    "eval_every = 200 # evaluate every 200 batches\n",
    "num_epochs = EPOCHS\n",
    "log_history = []  # To store logged metrics\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(training_loader)\n",
    "    \n",
    "    for step, batch in enumerate(tqdm.tqdm(training_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        label_mask = batch['label_mask'].to(device)\n",
    "\n",
    "        loss, _ = model(input_ids, attention_mask, labels, label_mask=label_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        global_step += 1\n",
    "\n",
    "        # Log training loss every 'log_every' steps\n",
    "        if (step + 1) % log_every == 0:\n",
    "            avg_loss = epoch_loss / (step + 1)\n",
    "            log_history.append({\n",
    "                \"step\": global_step,\n",
    "                \"loss\": avg_loss\n",
    "            })\n",
    "            print(f\"Step {global_step}: Avg Train Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        # Run evaluation every 'eval_every' steps\n",
    "        if (step + 1) % eval_every == 0:\n",
    "            eval_metrics = evaluate(model, testing_loader, device)\n",
    "            log_history.append({\n",
    "                \"step\": global_step,\n",
    "                \"eval_f1\": eval_metrics[\"f1\"],\n",
    "                \"eval_accuracy\": eval_metrics[\"accuracy\"],\n",
    "                \"eval_precision\": eval_metrics[\"precision\"],\n",
    "                \"eval_recall\": eval_metrics[\"recall\"],\n",
    "                \"eval_loss\": eval_metrics.get(\"eval_loss\", None)  # if you compute eval loss\n",
    "            })\n",
    "            print(f\"Step {global_step}: F1 = {eval_metrics['f1']:.4f}, Acc = {eval_metrics['accuracy']:.4f}, Prec = {eval_metrics['precision']:.4f}, Recall = {eval_metrics['recall']:.4f}\")\n",
    "\n",
    "    # End-of-epoch logging\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1} Completed: Avg Training Loss = {avg_epoch_loss:.4f}\")\n",
    "    eval_metrics = evaluate(model, testing_loader, device)\n",
    "    print(f\"Final: F1 = {eval_metrics['f1']:.4f}, Acc = {eval_metrics['accuracy']:.4f}, Prec = {eval_metrics['precision']:.4f}, Recall = {eval_metrics['recall']:.4f}\")\n",
    "    print(eval_metrics[\"f1_all\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebcdef-7f20-421c-8d42-77f5274c8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval():\n",
    "    train_steps, train_loss = [], []\n",
    "    eval_steps, eval_loss, f1s = [], [], []\n",
    "    \n",
    "    for entry in log_history:\n",
    "        if \"loss\" in entry and \"step\" in entry:\n",
    "            train_steps.append(entry[\"step\"])\n",
    "            train_loss.append(entry[\"loss\"])\n",
    "        if \"eval_f1\" in entry:\n",
    "            eval_steps.append(entry[\"step\"])\n",
    "            eval_loss.append(entry.get(\"eval_loss\", 0))  # or None if not computed\n",
    "            f1s.append(entry[\"eval_f1\"])\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if train_loss:\n",
    "        plt.plot(train_steps, train_loss, label=\"Train Loss\")\n",
    "    if eval_loss:\n",
    "        plt.plot(eval_steps, eval_loss, label=\"Eval Loss\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot F1\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if f1s[0] is not None:\n",
    "        plt.plot(eval_steps, f1s, label=\"Eval F1\", color='green')\n",
    "        plt.xlabel(\"Steps\")\n",
    "        plt.ylabel(\"F1 Score\")\n",
    "        plt.title(\"Evaluation F1 over Time\")\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e3ebe-7a25-4d4b-b053-c0957dccbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b57925-e639-493c-a56e-627f4f99f9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical_ner",
   "language": "python",
   "name": "clinical_ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
